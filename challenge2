import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
%matplotlib inline
import datetime
from sklearn.ensemble import RandomForestClassifier

from sklearn.preprocessing import LabelEncoder,OneHotEncoder
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.metrics import auc,confusion_matrix,accuracy_score,precision_recall_curve,precision_score,recall_score,f1_score
from sklearn.model_selection import validation_curve

data1=pd.read_csv('../input/dataset1/Final_Development set_With corrected dates and errors_Dimension1.csv')
data2=pd.read_csv('../input/dataset1/Final_Development set_With corrected dates and errors_Dimension2.csv')

data2.rename(columns={'Sucess' :'Success'}, inplace=True)

test1=pd.read_csv('../input/testdataset/test_dim_1_Without labels_Final.csv')
test2=pd.read_csv('../input/testdataset/test_dim_2_Without labels_Final.csv')

test2.rename(columns={'Sucess' :'Success'}, inplace=True)

A=data1.append(test1)
B=data2.append(test2)

B.head()
A.rename(columns= lambda x : x.lower().replace(".","_") , inplace= True)
B.rename(columns= lambda x : x.lower().replace(".","_") , inplace= True)



A['timestamp'] = A['ga_datehourminute'].map(lambda x: datetime.datetime.strptime(str(x), '%Y%m%d%H%M'))
B['timestamp'] = B['ga_datehourminute'].map(lambda x: datetime.datetime.strptime(str(x), '%Y%m%d%H%M'))


A.drop(columns='ga_datehourminute',inplace = True)
B.drop(columns='ga_datehourminute',inplace = True)



merge=pd.merge(A,B,on=['timestamp','ga_sessionswithevent','ga_sessiondurationbucket'])
merge.drop_duplicates()
merge.drop(['ga_uniquedimensioncombinations','unique_code','success_x'], 1, inplace=True)

data_merge=merge.iloc[0:-1].dropna()

test_data = merge[merge['success_y'].isnull()]

X=data_merge.iloc[:,:-1]
y=data_merge.iloc[:,-1]

lenc=LabelEncoder()
X['ga_usertype']=lenc.fit_transform(X['ga_usertype'])



X['ga_browser_encoded']=lenc.fit_transform(X['ga_browser_encoded'])
X['ga_operatingsystem_encoded']=lenc.fit_transform(X['ga_operatingsystem_encoded'])
X['ga_operatingsystemversion_encoded']=lenc.fit_transform(X['ga_operatingsystemversion_encoded'])
X['ga_language_encoded']=lenc.fit_transform(X['ga_language_encoded'])
X['ga_deviceinfo_encoded']=lenc.fit_transform(X['ga_deviceinfo_encoded'])

X=X.set_index('timestamp')

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

clf =  RandomForestClassifier(n_estimators=120,)
clf.fit(X_train,y_train)

clf.score(X_test,y_test)
y_pred=clf.predict(X_test)
from sklearn.metrics import auc,confusion_matrix,roc_curve,accuracy_score,precision_recall_curve,precision_score,recall_score,f1_score


cm=confusion_matrix(y_test,y_pred)
cm
ps=precision_score(y_test,y_pred)
precision, recall, _ = precision_recall_curve(y_test, y_pred)

plt.step(recall, precision, color='b', alpha=0.2,
         where='post')
plt.fill_between(recall, precision, step='post', alpha=0.2,
                 color='b')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('2-class Precision-Recall curve')
plt.show()


fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

roc_auc = auc(fpr, tpr)

lenc1=LabelEncoder()
lenc2=LabelEncoder()
lenc3=LabelEncoder()

lenc4=LabelEncoder()
lenc5=LabelEncoder()
lenc6=LabelEncoder()


test_data['ga_usertype']=lenc1.fit_transform(test_data['ga_usertype'])
test_data['ga_browser_encoded']=lenc2.fit_transform(test_data['ga_browser_encoded'])
test_data['ga_operatingsystem_encoded']=lenc3.fit_transform(test_data['ga_operatingsystem_encoded'])
test_data['ga_operatingsystemversion_encoded']=lenc4.fit_transform(test_data['ga_operatingsystemversion_encoded'])
test_data['ga_language_encoded']=lenc5.fit_transform(test_data['ga_language_encoded'])
test_data['ga_deviceinfo_encoded']=lenc6.fit_transform(test_data['ga_deviceinfo_encoded'])

test_data=test_data.set_index('timestamp')
test_data.drop(['success_y'], 1, inplace=True)


probability = clf.predict_proba(test_data)
test_data['success']=clf.predict(test_data)
test_data=test_data.reset_index()
result=pd.concat([pd.DataFrame(test_data),pd.DataFrame(probability)],axis=1)
result['ga_usertype']=lenc1.inverse_transform(result['ga_usertype'])
result['ga_browser_encoded']=lenc2.inverse_transform(result['ga_browser_encoded'])
result['ga_operatingsystem_encoded']=lenc3.inverse_transform(result['ga_operatingsystem_encoded'])
result['ga_operatingsystemversion_encoded']=lenc4.inverse_transform(result['ga_operatingsystemversion_encoded'])
result['ga_language_encoded']=lenc5.inverse_transform(result['ga_language_encoded'])
result['ga_deviceinfo_encoded']=lenc6.inverse_transform(result['ga_deviceinfo_encoded'])


print(result.info())

test_data.drop_duplicates()
print('f1_score : {}'.format(f1_score(y_test, y_pred)))
print('precision_score : {}'.format(precision_score(y_test,y_pred)))
print('confusion matrix : {}'.format(cm))
print(result.shape)
print(data_merge.shape)
print(merge.shape)
print(A.shape)
print(B.shape)

print(result.tail())

importances = clf.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf.estimators_],
             axis=0)
indices = np.argsort(importances)[::-1]
features = X.columns
# Print the feature ranking
print("Feature ranking:")

for f in range(X.shape[1]):
    print("%d. feature %s (%f)" % (f + 1, features[f], importances[indices[f]]))

# Plot the feature importances of the forest
plt.figure()
plt.title("Feature importances")
plt.bar(range(X.shape[1]), importances[indices],
       color="r", yerr=std[indices], align="center")
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation='vertical')
plt.xlim([-1, X.shape[1]])
plt.show()

